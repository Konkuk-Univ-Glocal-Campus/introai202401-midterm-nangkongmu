{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn # 파이토치의 신경망 모듈(nn)을 임포트\n",
    "import torch # torch, torch.optim, torch.nn.functional 모듈을 임포트하는데 PyTorch에서 모델을 구성하고 최적화하는 데 필요한 함수와 클래스를 제공\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FashionMNIST을 로드하고 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 이미지를 정규화함\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FashionMNIST 훈련 및 테스트 데이터셋 다운\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)  # 과제 조건 중 첫 번째 컨볼루션 레이어\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # 과제 조건 중 첫번째 풀링레이어\n",
    "        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)  # 과제 조건 중 두 번째 컨볼루션 레이어\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 과제 조건 중 두번째 풀링레이어\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 120)  # 과제 조건 중 첫 번째 완전 연결 레이어\n",
    "        self.fc2 = nn.Linear(120, 10)  # 과제 조건 중 두 번째 완전 연결 레이어\n",
    "        \n",
    "def forward(self, x): # 모델의 순전파를 정의하는 메서드로 입력 텐서 x가 모델을 통과하는 과정을 설명\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 첫 번째 컨볼루션 레이어와 풀링 레이어를 통과\n",
    "        x = self.pool2(F.relu(self.conv2(x)))  # 두 번째 컨볼루션 레이어와 풀링 레이어를 통과\n",
    "        x = x.view(-1, 16 * 7 * 7)  # 평탄화\n",
    "        x = F.relu(self.fc1(x))  # 첫 번째 완전 연결 레이어를 통과\n",
    "        x = self.fc2(x)  # 두 번째 완전 연결 레이어를 통과\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화 진행\n",
    "model = pyCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch를 사용하여 신경망 모델을 학습하고 검증하는 과정을 구현\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=5): # 함수를 정의하여 모델, 학습 데이터 로더, 테스트 데이터 로더, 그리고 에폭 수를 매개변수로 받음\n",
    "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []} \n",
    "\n",
    "    # 에폭 수만큼 반복하면서 모델의 학습 및 평가를 수행하는데 학습 시에는 model.train()을 호출하여 모델을 학습 모드로 설정하고, 평가 시에는 model.eval()을 호출하여 평가 모드로 설정\n",
    "    for epoch in range(epochs):\n",
    "        # 모델의 학습\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "        \n",
    "        # 모델의 평가\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_correct = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                test_loss += loss.item() * images.size(0) # 정확도와 손실을 기록, 진행 상황 모니터링\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                test_correct += (predicted == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "        \n",
    "        # 평균 손실과 정확도\n",
    "        epoch_train_loss = train_loss / total_train\n",
    "        epoch_train_acc = 100 * train_correct / total_train\n",
    "        epoch_test_loss = test_loss / total_test\n",
    "        epoch_test_acc = 100 * test_correct / total_test\n",
    "        \n",
    "        # history에 저장\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['test_loss'].append(epoch_test_loss)\n",
    "        history['test_acc'].append(epoch_test_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{epochs}: Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%, Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.2f}%')\n",
    "    \n",
    "    return history # 학습과 테스트 과정에서의 손실과 정확도를 기록한 history 딕셔너리를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# 신경망 모델을 학습시키고 그 결과를 처리하는 과정을 보여줌\n",
    "def plot_metrics(history):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['test_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Over Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['test_acc'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Over Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 함수를 호출하여 신경망 모델을 학습시키는데 총 5 에폭(epoch) 동안 학습을 수행하고 학습 과정에서 계산된 손실과 정확도 같은 통계 정보를 history 변수에 저장\n",
    "history = train_model(model, train_loader, test_loader, criterion, optimizer, epochs=5)\n",
    "plot_metrics(history) # plot_metrics 함수를 호출하여 history에 저장된 학습 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [pyCNN] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;66;03m# 순전파\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(images)  \u001b[38;5;66;03m# 모델 호출 방식 수정\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         probabilities \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 소프트맥스 함수 적용\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;66;03m# 손실 계산\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gadin\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:374\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    364\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing the required \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Module [pyCNN] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "num_epochs = 5  # 예시로 5로 설정\n",
    "total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 순전파\n",
    "        outputs = model.forward(images)  # 모델 호출 방식 수정\n",
    "        probabilities = F.softmax(outputs, dim=1)  # 소프트맥스 함수 적용\n",
    "        \n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 역전파 및 최적화\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 훈련 과정에서의 손실 및 정확도 모니터링\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
